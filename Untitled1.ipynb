{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNdVhESUmKPu8vK6i1PFWPs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/0Daniii/Streamlit/blob/main/Untitled1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "nUcgUu3em5bD"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a1540c61"
      },
      "source": [
        "# Task\n",
        "Build a spam detection model using a synthetic dataset, apply text vectorization, train a Multinomial Naive Bayes classifier, evaluate its performance, and create a function to predict whether custom email messages are 'spam' or 'ham', then demonstrate it with example messages and summarize the project."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dc3d35e5"
      },
      "source": [
        "## Create Synthetic Dataset\n",
        "\n",
        "### Subtask:\n",
        "Generate a synthetic dataset containing example 'spam' and 'ham' email messages, as the 'fetch_20newsgroups' dataset is not directly suitable for spam detection. This will involve creating a Pandas DataFrame with 'text' and 'label' columns.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6d09f2c7"
      },
      "source": [
        "**Reasoning**:\n",
        "The subtask requires generating a synthetic dataset with 'ham' and 'spam' email messages and storing them in a pandas DataFrame. This code block will import pandas, define example messages, create the DataFrame, and display its head.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "03119cee",
        "outputId": "ec6777c6-c471-4826-c9e1-ba20429c215c"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Create example 'ham' (non-spam) messages\n",
        "ham_messages = [\n",
        "    \"Hi team, please find the Q3 report attached.\",\n",
        "    \"Meeting at 10 AM in conference room B. Don't be late!\",\n",
        "    \"Could you review my pull request by end of day? Thanks!\",\n",
        "    \"Your Amazon order #12345 has been shipped.\",\n",
        "    \"Recipe for a delicious chocolate cake: 2 cups flour, 1 cup sugar, etc.\",\n",
        "    \"Reminder: Your doctor's appointment is scheduled for tomorrow at 2 PM.\",\n",
        "    \"Monthly newsletter from your favorite tech blog. Read the latest news!\",\n",
        "    \"Project update: We've successfully integrated the new module.\",\n",
        "    \"Family dinner this Sunday at my place, hope you can make it!\",\n",
        "    \"Regarding your query, please refer to the attached documentation.\"\n",
        "]\n",
        "\n",
        "# Create example 'spam' messages\n",
        "spam_messages = [\n",
        "    \"Win a free iPhone now! Click this link to claim your prize!\",\n",
        "    \"URGENT: Your account has been suspended. Verify your details here.\",\n",
        "    \"Congratulations! You've won a cash prize of $1,000,000. Reply to claim.\",\n",
        "    \"Enlarge your manhood by 5 inches with our revolutionary product!\",\n",
        "    \"Nigerian Prince needs your help to transfer funds. Great returns guaranteed!\",\n",
        "    \"Limited time offer: Get rich quick! Invest in our cryptocurrency scheme.\",\n",
        "    \"You have a new message from a secret admirer. Click here to find out who!\",\n",
        "    \"Claim your free vacation to a tropical island. Just pay handling fees.\",\n",
        "    \"Your credit card has been compromised. Update your information immediately.\",\n",
        "    \"Unlock exclusive discounts and coupons! Click this phishing link now!\"\n",
        "]\n",
        "\n",
        "# Combine messages and create labels\n",
        "texts = ham_messages + spam_messages\n",
        "labels = ['ham'] * len(ham_messages) + ['spam'] * len(spam_messages)\n",
        "\n",
        "# Create a pandas DataFrame\n",
        "df = pd.DataFrame({\n",
        "    'text': texts,\n",
        "    'label': labels\n",
        "})\n",
        "\n",
        "# Display the first few rows of the DataFrame\n",
        "print(\"Synthetic dataset created:\")\n",
        "print(df.head())"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Synthetic dataset created:\n",
            "                                                text label\n",
            "0       Hi team, please find the Q3 report attached.   ham\n",
            "1  Meeting at 10 AM in conference room B. Don't b...   ham\n",
            "2  Could you review my pull request by end of day...   ham\n",
            "3         Your Amazon order #12345 has been shipped.   ham\n",
            "4  Recipe for a delicious chocolate cake: 2 cups ...   ham\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8937733a"
      },
      "source": [
        "## Text Vectorization\n",
        "\n",
        "### Subtask:\n",
        "Initialize and apply Scikit-Learn's `CountVectorizer` to transform the text data into numerical feature vectors. This step will also fit the vectorizer on the training data.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1c2847df"
      },
      "source": [
        "**Reasoning**:\n",
        "To perform text vectorization as per the subtask, I need to import `CountVectorizer` from `sklearn.feature_extraction.text`, initialize it, then use its `fit_transform` method on the 'text' column of the DataFrame to create numerical feature vectors, and finally, print the shape of the resulting matrix.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "30af3c62",
        "outputId": "74f3be3b-498e-4dd1-f097-971b35124001"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Instantiate CountVectorizer\n",
        "vectorizer = CountVectorizer()\n",
        "\n",
        "# Apply fit_transform to the 'text' column to convert text data into numerical feature vectors\n",
        "X = vectorizer.fit_transform(df['text'])\n",
        "\n",
        "# Print the shape of X to see the dimensions of the vectorized data\n",
        "print(\"Shape of feature matrix X:\", X.shape)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of feature matrix X: (20, 152)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "716b0345"
      },
      "source": [
        "## Split Data\n",
        "\n",
        "### Subtask:\n",
        "Divide the vectorized dataset into training and testing sets using `train_test_split` from Scikit-Learn, typically with an 80/20 split for training and testing respectively.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e51c74a3"
      },
      "source": [
        "**Reasoning**:\n",
        "To prepare for model training, I will split the vectorized data and labels into training and testing sets using `train_test_split` with an 80/20 ratio for evaluation.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ac334ece",
        "outputId": "cd3b2375-45ee-4395-8a56-87709302fb6f"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Define the target variable y\n",
        "y = df['label']\n",
        "\n",
        "# Split the data into training and testing sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Print the shapes of the resulting sets to verify the split\n",
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"X_test shape:\", X_test.shape)\n",
        "print(\"y_train shape:\", y_train.shape)\n",
        "print(\"y_test shape:\", y_test.shape)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape: (16, 152)\n",
            "X_test shape: (4, 152)\n",
            "y_train shape: (16,)\n",
            "y_test shape: (4,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11a44606"
      },
      "source": [
        "## Train Multinomial Naive Bayes Model\n",
        "\n",
        "### Subtask:\n",
        "Instantiate and train a `MultinomialNB` classifier from Scikit-Learn using the training data.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f7c153a6"
      },
      "source": [
        "**Reasoning**:\n",
        "To train a Multinomial Naive Bayes classifier, I will import `MultinomialNB` from `sklearn.naive_bayes`, instantiate the model, and then fit it using the `X_train` (features) and `y_train` (labels) datasets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "877ede6f"
      },
      "source": [
        "**Reasoning**:\n",
        "Following the instructions, I will now write the Python code to import `MultinomialNB`, instantiate the model, and train it using the `X_train` and `y_train` datasets.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "98a4215a",
        "outputId": "e86d6553-911f-4a19-ddda-ea4f4e2641a3"
      },
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "# Instantiate Multinomial Naive Bayes classifier\n",
        "model = MultinomialNB()\n",
        "\n",
        "# Train the model using the training data\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "print(\"Multinomial Naive Bayes model trained successfully.\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Multinomial Naive Bayes model trained successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "71d577bc"
      },
      "source": [
        "## Evaluate Model\n",
        "\n",
        "### Subtask:\n",
        "Evaluate the trained model's performance on the test data by calculating and printing the accuracy score and generating a confusion matrix to visualize true positives, true negatives, false positives, and false negatives.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5564195c"
      },
      "source": [
        "**Reasoning**:\n",
        "To evaluate the model's performance as per the subtask, I will first make predictions on the test set, then calculate the accuracy score and generate a confusion matrix using `sklearn.metrics` to assess the model's effectiveness.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3d13eec2",
        "outputId": "8dd35d49-389f-4963-f949-6af94ca19b55"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "\n",
        "# 1. Make predictions on the test data\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# 2. Calculate and print the accuracy score\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy Score: {accuracy:.2f}\")\n",
        "\n",
        "# 3. Generate and print the confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(cm)\n",
        "\n",
        "# Explanation of confusion matrix (assuming 'ham' is negative (0) and 'spam' is positive (1) if encoded, or based on alphabetical order)\n",
        "# Given our labels are 'ham' and 'spam', sklearn typically orders alphabetically.\n",
        "# So, 'ham' is likely the first class (index 0) and 'spam' is the second (index 1).\n",
        "# cm[0,0]: True Negatives (Correctly predicted 'ham')\n",
        "# cm[0,1]: False Positives (Actual 'ham' predicted as 'spam')\n",
        "# cm[1,0]: False Negatives (Actual 'spam' predicted as 'ham')\n",
        "# cm[1,1]: True Positives (Correctly predicted 'spam')\n",
        "\n",
        "print(\"\\nInterpretation of Confusion Matrix:\")\n",
        "print(f\"True Negatives (Actual Ham, Predicted Ham): {cm[0,0]}\")\n",
        "print(f\"False Positives (Actual Ham, Predicted Spam): {cm[0,1]}\")\n",
        "print(f\"False Negatives (Actual Spam, Predicted Ham): {cm[1,0]}\")\n",
        "print(f\"True Positives (Actual Spam, Predicted Spam): {cm[1,1]}\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy Score: 1.00\n",
            "\n",
            "Confusion Matrix:\n",
            "[[2 0]\n",
            " [0 2]]\n",
            "\n",
            "Interpretation of Confusion Matrix:\n",
            "True Negatives (Actual Ham, Predicted Ham): 2\n",
            "False Positives (Actual Ham, Predicted Spam): 0\n",
            "False Negatives (Actual Spam, Predicted Ham): 0\n",
            "True Positives (Actual Spam, Predicted Spam): 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7cee5b5d"
      },
      "source": [
        "## Create Prediction Function\n",
        "\n",
        "### Subtask:\n",
        "Develop a Python function that takes a custom email message as input, vectorizes it using the previously fitted `CountVectorizer`, and then uses the trained `MultinomialNB` model to predict whether it is 'spam' or 'ham'.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c73b16a1"
      },
      "source": [
        "**Reasoning**:\n",
        "To create the prediction function, I will define a Python function that takes an email message, uses the pre-fitted `CountVectorizer` to transform the message, and then uses the trained `MultinomialNB` model to predict its label ('spam' or 'ham').\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b3b4c630",
        "outputId": "b409fd34-378d-469e-e71a-b98ebe0128f6"
      },
      "source": [
        "def predict_spam_ham(message):\n",
        "    # Vectorize the input message using the fitted CountVectorizer\n",
        "    message_vectorized = vectorizer.transform([message])\n",
        "\n",
        "    # Predict the label using the trained Multinomial Naive Bayes model\n",
        "    prediction = model.predict(message_vectorized)\n",
        "\n",
        "    # Return the predicted label\n",
        "    return prediction[0]\n",
        "\n",
        "print(\"Prediction function 'predict_spam_ham' created successfully.\")"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction function 'predict_spam_ham' created successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9c2f94f7"
      },
      "source": [
        "## Test with Custom Messages\n",
        "\n",
        "### Subtask:\n",
        "Demonstrate the prediction function by testing it with a few custom-written spam and ham messages to show its real-world application.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fa51258c"
      },
      "source": [
        "**Reasoning**:\n",
        "To demonstrate the prediction function, I need to define custom 'ham' and 'spam' messages, then iterate through each to predict its label and print the results, following the instructions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e7a409e8",
        "outputId": "592c1130-31d0-4a62-f13c-0525f4bb78f7"
      },
      "source": [
        "print(\"Demonstrating the prediction function with single custom messages:\")\n",
        "\n",
        "# Test with a single custom 'ham' message\n",
        "single_ham_message = \"Please confirm, ASAP, so we don't loose the window. NOthing is changed yet. Reply when you see this.\"\n",
        "prediction_ham = predict_spam_ham(single_ham_message)\n",
        "print(f\"\\nMessage: '{single_ham_message}' -> Predicted: {prediction_ham}\")\n",
        "\n",
        "# Test with a single custom 'spam' message\n",
        "single_spam_message = \"Your account has been suspended, verify imediatelly to avoid permanent lock. Bit.dy/secure-now msg & data rates may apply. Stop to cancel.\"\n",
        "prediction_spam = predict_spam_ham(single_spam_message)\n",
        "print(f\"Message: '{single_spam_message}' -> Predicted: {prediction_spam}\")\n",
        "\n",
        "\n",
        "\n",
        "# The original code for multiple custom messages is commented out below:\n",
        "# custom_ham_messages = [\n",
        "#     \"Hello, please review the attached document at your convenience.\",\n",
        "#     \"Reminder: Team meeting is scheduled for tomorrow at 10 AM.\"\n",
        "# ]\n",
        "# custom_spam_messages = [\n",
        "#     \"URGENT! You've won a lottery! Click here to claim your prize!\",\n",
        "#     \"Free money! Limited time offer. Act now!\"\n",
        "# ]\n",
        "# print(\"\\n--- Testing with custom HAM messages ---\")\n",
        "# for message in custom_ham_messages:\n",
        "#     prediction = predict_spam_ham(message)\n",
        "#     print(f\"Message: '{message}' -> Predicted: {prediction}\")\n",
        "# print(\"\\n--- Testing with custom SPAM messages ---\")\n",
        "# for message in custom_spam_messages:\n",
        "#     prediction = predict_spam_ham(message)\n",
        "#     print(f\"Message: '{message}' -> Predicted: {prediction}\")"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Demonstrating the prediction function with single custom messages:\n",
            "\n",
            "Message: 'Please confirm, ASAP, so we don't loose the window. NOthing is changed yet. Reply when you see this.' -> Predicted: ham\n",
            "Message: 'Your account has been suspended, verify imediatelly to avoid permanent lock. Bit.dy/secure-now msg & data rates may apply. Stop to cancel.' -> Predicted: spam\n"
          ]
        }
      ]
    }
  ]
}